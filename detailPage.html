<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Detail Page</title>
    <meta charset="utf-8">
    <link rel="stylesheet" href="css/common.css">
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/detailPage.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.3/css/all.css" integrity="sha384-SZXxX4whJ79/gErwcOYf+zWLeJdY/qpuqC4cAa9rOGUstPomtqpuNWT9wdPEn2fk" crossorigin="anonymous">

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Didact+Gothic&display=swap" rel="stylesheet">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/momentjs/latest/moment.min.js"></script>

    <script src="https://www.gstatic.com/firebasejs/8.6.5/firebase-app.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.6.5/firebase-database.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.6.5/firebase-analytics.js"></script>
    <script src="firebase.js"></script>
    
    <!-- <script src="script/load.js"></script> -->
    <script src="script/main.js"></script>
</head>
<body>
  <div class="container">
    <nav>
        <div class="logo"></div>

        <div class="nav_tab">
            <a href="">Home</a>
            <a href="">Recommendation</a>
            <a href="">Community</a>
        </div>
        <div class="search">
            <input type="text" name="search" placeholder="search">
            <p></p>
        </div>
        <div class="icons">
            <p></p>
            <p></p>
            <p></p>
        </div>
    </nav>
    <div class="paper_info">
        <div id="title"> 
            <h1>Breaking The Experience: Effects of Questionnaires in VR User Studies</h1>
            <aside>
                <span class="thumb"></span>
                <span class="cart"></span>
            </aside>
        </div>
        <div id="subsection">
            <div id="more_info">
                <ul>
                <li class="info_list">
                    Publication : 
                    <div id="publication">CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</div>
                </li>
                <li class="info_list">
                    Authors : 
                    <ul id="authors">
                        <li>Susanne Putze</li>
                        <li>Dmitry Alexandrovsky</li>
                        <li>Felix Putze</li>
                        <li>Sebastian Höffner</li>
                        <li>Jan David Smeddinck</li>
                        <li>Rainer Malaka</li>
                    </ul>
                </li>
                <li class="info_list">
                    DOI : 
                    <div id="doi"><a href="https://doi.org/10.1145/3313831.3376144">https://doi.org/10.1145/3313831.3376144</a></div>
                </li>
                </ul>
            </div>
            <div id="icon">
                <span class="cite">21</span>
                <span class="down">200</span>
                <span class="graph">graph</span>
            </div>
        </div>
    </div>
    <div class="paper_detail">
        <div id="left">
            <div id="figure_selected">
                <img src="../img/1_1.png" alt="main figure">
                <!-- <i class="fas fa-caret-up"></i> -->
                <div id="figure_caption">Figure 3. A user wearing the HMD and biosensors.</div>
            </div>
            <div id="figure_list">

            </div>
        </div>
        <div id="right">
            <div class="subtitle">Recording of Physiological Signals</div>
            <div class="body">We used a Mind Media NeXus 10 MKII biofeedback device1 with the BioTrace+ V2018A software for recording of the physiological signals with a sampling rate of 128 Hz. The NeXus 10 was connected using a 5 m USB cable allowing the participants to move around freely in the tracking space. We used a chest strap respiration sensor, a blood volume pressure (BVP) sensor and a skin conductance (SC) sensor to measure electrodermal activity (EDA) on the non-dominant hand of the participant. These biosignals are in alignment with physiological measures of presence [53, 58, 59] and BIP [54, 85, 86].</div>
            <div class="body">Figure 3 illustrates the recording setup: We attached the SC sensors using adjustable velcro straps to the middle phalanx of ring and little finger which have the highest SC responsiveness [77, 97]. To synchronize the recordings of the signals with the game, we used audio signals and manual triggers. Before placement of the electrodes, the participants cleaned their non-dominant hand with a wet wipe. To get a clear signal quality and reduce artifacts due to movement, we briefed the participants not to use their non-dominant hand with the sensors and to let it hang down during the whole study. A conductor helped the participants with fitting the HMD.</div>
            <div class="subtitle">Subjective Measures</div>
            <div class="body">To assess player experience after each game round, we applied the Player Experience of Need of Satisfaction (PENS) [66] questionnaire either using an inVRQ or outVRQ. It consists of 21 items on a 7-point Likert scale with the subscales of autonomy, competence, relatedness, presence, and intuitive control. With 21 items PENS is similar in length to other questionnaires (e.g. PANAS, IPQ, NASA-TLX) used in previous user studies with inVRQs [45, 63, 76]. To assess potential differences in perceived sense of presence due to different questionnaire modalities and to validate the “breakable experience”, we operated the igroup presence questionnaire (IPQ) [70] after the third game rounds in each condition (2 × for each participant). The IPQ consists of 14 items on a 5-point Likert scale with the subscales General Presence (GP), Spatial Presence (SP), Involvement (INV) and Realism (REAL). We did not assess the IPQ between trials because it is not sensitive for measuring a BIP [3, 74] and the game rounds did not differ. We also collected self reports about game experience and usability with both questionnaire modalities. Finally, the users ranked the BIP events by the degree of distraction.</div>
            <div class="subtitle">Procedure and Tasks</div>
            <div class="body">Our study ﬂow is depicted in Figure 2 and consisted of the following states:  1.  Study  preparation:  Brieﬁng  and  complete consent form. Random assignment to a condition (HiFi or  LoFi)  and  order  of  the  questionnaire  modality.  Attach physiological  sensors  and synchronize  biosignals  with the game. Put on the HMD. 2. First questionnaire condition, steps A.-H. (INVRQ or OUTVRQ). 3. Break (optional). 4. Second questionnaire condition, steps A.–H. (OUTVRQ or INVRQ). 5. Conclusive questionnaire on a PC with demographics, ranking questionnaire modalities and debrieﬁng.</div>
            <div class="body">Each questionnaire condition contained the following steps: A. Put on the HMD and play a tutorial round (60s). B. Initial blackout BIP. C. Game round #1 (90s). D. PENS #1 using INVRQ or OUTVRQ depending on the condition. E. Game round #2 (90s). F. PENS #2 using same questionnaire modality as PENS #1. G. Game round #3 (90s). H. Take off the HMD and fill out an IPQ on the PC. The whole procedure required around 45min with an average in-VR time of 17.35min (SD=1.45). The study took place in a lab room without irregular light, climate or noise conditions.</div>
        </div>
        <div id="progress_bar">
            progress bar
        </div>
    </div>
</div>
<script src="cardFactory.js"></script>
  
</body>
</html>