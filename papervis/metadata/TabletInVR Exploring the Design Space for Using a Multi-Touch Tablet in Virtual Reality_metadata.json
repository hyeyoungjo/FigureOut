{
    "fullpath": "/Users/takyeonlee/Documents/work/_\u1109\u116e\u110b\u1165\u11b8_2021/ID503_Design_Project_1/_PaperVis/papers/chi2019xr/TabletInVR Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality.pdf",
    "paper_id": "TabletInVR Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality",
    "venue": "chi2019xr",
    "keywords": [
        "Interaction techniques",
        "Virtual reality",
        "Touch interaction"
    ],
    "paragraph_containing_keyword": "KEYWORDS\ninteraction techniques, virtual reality, touch interaction\nACM Reference Format:\nHemant Bhaskar Surale, Aakar Gupta, Mark Hancock, and Daniel\nVogel. 2019. TabletInVR: Exploring the Design Space for Using a\nMulti-Touch Tablet in Virtual Reality. In CHI Conference on Human\nFactors in Computing Systems Proceedings (CHI 2019), May 4\u20139, 2019,\nGlasgow, Scotland UK. ACM, New York, NY, USA, 13 pages. https:\n//doi.org/10.1145/3290605.3300243\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear\nthis notice and the full citation on the first page. Copyrights for components\nof this work owned by others than ACM must be honored. Abstracting with\ncredit is permitted. To copy otherwise, or republish, to post on servers or to\nredistribute to lists, requires prior specific permission and/or a fee. Request\npermissions from permissions@acm.org.\nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK\n\u00a9 2019 Association for Computing Machinery.\nACM ISBN 978-1-4503-5970-2/19/05.\nhttps://doi.org/10.1145/3290605.3300243",
    "doi": "10.1145/3290605.3300243",
    "paragraph_after_keyword": "1 INTRODUCTION\nWhile virtual reality (VR) has been around in various forms\nsince at least the 1960s (e.g., [54]), advances in display tech-\nnology have sparked a new interest from both researchers\nand the public. There are clear advantages to virtual reality,\nlike the ability to look and move around in an immersive 3D\nenvironment. Yet, VR interaction is challenging due to lim-\nited tactile feedback, poor input precision when drawing [2],\nand lack of a consistent interaction vocabulary. Past research\nhas introduced methods for haptic feedback [5, 16, 37, 52, 60],\ntechniques to increase precision [43], and more standardized\ncontrol schemes [49]. In our work, we leverage the familiarity\nand ubiquity of multi-touch tablets as a means of interacting\nwith 3D content in a VR world.\nWe introduce a \u201cTabletInVR\u201d design space combining a\n3D-tracked tablet with mid-air barehand gestures, which we\ndemonstrate in an example interaction vocabulary for 3D\nmodelling.\nExploring VR interaction in the context of 3D modelling is\nparticularly compelling because the task should be a good fit\nfor VR, but in practice, supporting the many required opera-\ntions is challenging (e.g. object creation, selection, transfor-\nmation; world navigation; copy, paste, undo, etc.). Although\npast research has considered the use of 2D surfaces in VR, this\nhas focused on 3D-tracked props without real multi-touch in-\nput [34, 35, 44], or using multi-touch tablets for transforming\n3D objects without exploiting 3D tablet tracking [15, 46].\nOur work combines the affordances of a 3D-tracked tablet\nwith the input capabilities of its multi-touch surface. We ad-\nvocate that the tablet\u2019s precise touch input capability, physi-\ncal shape, metaphorical associations, and natural compatibil-\nity with barehand, mid-air input can be effectively used in\nVR. Interactions involving precise mutli-touch input could\nbegin on the tablet followed by coarse hand gestures in VR,\nor tablet input could be used to transform objects or navi-\ngate the world in a familiar mutli-touch way. This suggests\ninteresting aspects when combining these two modalities.\nInteractions can leverage physical qualities like the 2D tablet\ninput providing a continuous tactile sensation and a mid-air",
    "sections": [
        {
            "word_count": 501,
            "figure_citations": {},
            "section_index": 0,
            "title": "INTRODUCTION"
        },
        {
            "word_count": 723,
            "figure_citations": {},
            "section_index": 1,
            "title": "BACKGROUND AND RELATED WORK"
        },
        {
            "word_count": 1046,
            "figure_citations": {},
            "section_index": 2,
            "title": "FORMATIVE STUDY"
        },
        {
            "word_count": 1273,
            "figure_citations": {},
            "section_index": 3,
            "title": "DESIGN SPACE"
        },
        {
            "word_count": 2384,
            "figure_citations": {
                "1": [
                    "Figure 1)."
                ],
                "2": [
                    "Figure 2)."
                ],
                "3": [
                    "Figure 3, described in TapSense [25] and in the modeswitching study by Surale et al.",
                    "Figure 3 (b-c))."
                ],
                "4": [
                    "Figure 4 (a)).",
                    "Figure 4(b-c)) follow selection, and can be performed simultaneously."
                ],
                "5": [
                    "Figure 5) (O1, O3, O5, O6, D9).",
                    "Figure 5)."
                ],
                "6": [
                    "Figure 6 (a)).",
                    "Figure 6 (b)), and while navigating, the scene quickly fades to black, except for the tablet and viewport.",
                    "Figure 6 (c)) and query into the mic (O4)."
                ]
            },
            "section_index": 4,
            "title": "EXAMPLE INTERACTION VOCABULARY"
        },
        {
            "word_count": 1555,
            "figure_citations": {
                "7": [
                    "Figure 7 (a).",
                    "Figure 7 (b-g)).",
                    "Figure 7 (h-k))."
                ]
            },
            "section_index": 5,
            "title": "USER EVALUATION"
        },
        {
            "word_count": 154,
            "figure_citations": {},
            "section_index": 6,
            "title": "CONCLUSION"
        },
        {
            "word_count": 31,
            "figure_citations": {},
            "section_index": 7,
            "title": "ACKNOWLEDGEMENTS"
        },
        {
            "word_count": 2070,
            "figure_citations": {},
            "section_index": 8,
            "title": "REFERENCES"
        }
    ],
    "title": "TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality",
    "authors": "Hemant Bhaskar Surale, Aakar Gupta, Mark Hancock, Daniel Vogel",
    "abstract": "Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, \"cutting\" objects by using the tablet as a physical \"knife\", navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach.",
    "publication": {
        "venue": "N/A",
        "venue_full": "Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
        "year": "2019",
        "date": "2019/5/2"
    },
    "version": 4
}