{
    "fullpath": "/Users/takyeonlee/Documents/work/_\u1109\u116e\u110b\u1165\u11b8_2021/ID503_Design_Project_1/_PaperVis/papers/chi2019xr/Affinity Lens Data-Assisted Affinity Diagramming with Augmented Reality.pdf",
    "paper_id": "Affinity Lens Data-Assisted Affinity Diagramming with Augmented Reality",
    "venue": "chi2019xr",
    "keywords": [
        "Affinity diagrams",
        "Visual analytics",
        "Augmented reality"
    ],
    "paragraph_containing_keyword": "supports easy switching between qualitative and quantita-\ntive \u2018views\u2019 of data, without surrendering the lightweight\nbenefits of existing AD practice.\nCCS CONCEPTS\n\u2022 Human-centered computing \u2192 HCI design and eval-\nuation methods; Visual analytics; Mixed / augmented re-\nality; Visualization systems and tools.\nKEYWORDS\naffinity diagrams; visual analytics; augmented reality\nACM Reference Format:\nHariharan  Subramonyam,  Steven  M.  Drucker,  and  Eytan  Adar. \n2019. Affinity Lens: Data-Assisted Affinity Diagramming with Aug-\nmented Reality. In Proceedings of CHI Conference on Human Factors \nin Computing Systems Proceedings (CHI 2019) May 4\u20139, 2019, \nGlasgow, Scotland UK. ACM, New York, NY, USA, 13 pages. https://\ndoi.org/10.1145/3290605.3300628\n1 \nINTRODUCTION\nAffinity Diagrams (AD) and related approaches are the method \nof choice for many designers and UX researchers. AD sup-\nports analysis and synthesis of interview notes, brainstorm-\ning, creating user personas, and evaluating interactive proto-\ntypes [24]. Notes can be placed on walls or surfaces in a way \nthat leverages spatial cognition, offers flexibility in grouping \nand clustering, and then physically persists. Both individu-\nals and groups can participate on large shared surfaces. AD \nusers  work  to  derive  structure  from  inherently  fuzzy  and \nseemingly unstructured input. Though software tools have",
    "paragraph_after_keyword": "Permission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear\nthis notice and the full citation on the first page. Copyrights for components\nof this work owned by others than ACM must be honored. Abstracting with\ncredit is permitted. To copy otherwise, or republish, to post on servers or to\nredistribute to lists, requires prior specific permission and/or a fee. Request\npermissions from permissions@acm.org.\nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK\n\u00a9 2019 Association for Computing Machinery.\nACM ISBN 978-1-4503-5970-2/19/05. . . $15.00\nhttps://doi.org/10.1145/3290605.3300628",
    "doi": "10.1145/3290605.3300628",
    "sections": [
        {
            "word_count": 674,
            "figure_citations": {
                "1": [
                    "Figure 1a).",
                    "Figure 1b), the designer can use the phone to look at distributions of sleeping schedules for each cluster (Figure 1c)."
                ]
            },
            "section_index": 0,
            "title": "INTRODUCTION"
        },
        {
            "word_count": 1029,
            "figure_citations": {},
            "section_index": 1,
            "title": "RELATED WORK"
        },
        {
            "word_count": 1070,
            "figure_citations": {},
            "section_index": 2,
            "title": "A DESIGN PROBE FOR DAAD"
        },
        {
            "word_count": 475,
            "figure_citations": {},
            "section_index": 3,
            "title": "DESIGN GUIDELINES"
        },
        {
            "word_count": 547,
            "figure_citations": {
                "2": [
                    "Figure 2 captures the four main regions of the mobile interface: the largest, is dedicated to the camera and visualization augmentation (a), a contextual menu occupies the right edge of the display (b) and dynamically changes depending on what is present in the camera\u2019s field of view, a data attribute Paper 398 CHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK a b d cook eatout housing emp grade exercise c Figure 2: Affinity Lens User Interface."
                ],
                "3": [
                    "Figure 3) we follow a designer, Dave, as he uses DAAD to analyze the food choice dataset (this example is based on a combination of real use cases from our user studies).",
                    "Figure 3a).",
                    "Figure 3b)."
                ],
                "4": [
                    "Figure 4 a)."
                ]
            },
            "section_index": 4,
            "title": "USER EXPERIENCE"
        },
        {
            "word_count": 890,
            "figure_citations": {
                "4": [
                    "Figure 4 b).",
                    "Figure 4 f).",
                    "Figure 4) to support common tasks."
                ],
                "3": [
                    "Figure 3 d) so he can continue working without pointing at the physical notes (D2, D3).",
                    "Figure 3 e) and alerts him that all but one student in the on-campus sub-cluster are first years (D4)."
                ]
            },
            "section_index": 5,
            "title": "PRINT"
        },
        {
            "word_count": 2,
            "figure_citations": {},
            "section_index": 6,
            "title": "STILL IMAGE"
        },
        {
            "word_count": 1140,
            "figure_citations": {
                "4": [
                    "Figure 4i).",
                    "Figure 4c) displays those data values that are the same and those that are different (a weak representation of affinity).",
                    "Figure 4d) will generate an overlay of common words (sized by frequency) on top of the notes.",
                    "Figure 4g).",
                    "Figure 4h)."
                ],
                "1": [
                    "Figure 1a)."
                ]
            },
            "section_index": 7,
            "title": "LIVE"
        },
        {
            "word_count": 979,
            "figure_citations": {
                "5": [
                    "Figure 5, Affinity Lens is comprised of five main components: (1) Scene Analyzer, (2) Lens Controller, (3) Dynamic View Configurator, (4) lenses, and (5) the Data Access and Analytics Module."
                ]
            },
            "section_index": 8,
            "title": "SYSTEM ARCHITECTURE"
        },
        {
            "word_count": 1834,
            "figure_citations": {},
            "section_index": 9,
            "title": "EVALUATION"
        },
        {
            "word_count": 462,
            "figure_citations": {},
            "section_index": 10,
            "title": "DISCUSSION AND FUTURE WORK"
        },
        {
            "word_count": 130,
            "figure_citations": {},
            "section_index": 11,
            "title": "CONCLUSION"
        },
        {
            "word_count": 475,
            "figure_citations": {},
            "section_index": 12,
            "title": "REFERENCES"
        },
        {
            "word_count": 1068,
            "figure_citations": {},
            "section_index": 13,
            "title": "ACKNOWLEDGMENTS"
        }
    ],
    "title": "Affinity Lens: Data-Assisted Affinity Diagramming with Augmented Reality",
    "authors": "Hariharan Subramonyam, Steven M. Drucker, Eytan Adar",
    "abstract": "Despite the availability of software to support Affinity Diagramming (AD), practitioners still largely favor physical sticky-notes. Physical notes are easy to set-up, can be moved around in space and offer flexibility when clustering un-structured data. However, when working with mixed data sources such as surveys, designers often trade off the physicality of notes for analytical power. We propose AffinityLens, a mobile-based augmented reality (AR) application for Data-Assisted Affinity Diagramming (DAAD). Our application provides just-in-time quantitative insights overlaid on physical notes. Affinity Lens uses several different types of AR overlays (called lenses) to help users find specific notes, cluster information, and summarize insights from clusters. Through a formative study of AD users, we developed design principles for data-assisted AD and an initial collection of lenses. Based on our prototype, we find that Affinity Lens supports easy switching between qualitative and quantitative 'views' of data, without surrendering the lightweight benefits of existing AD practice.",
    "publication": {
        "venue": "N/A",
        "venue_full": "Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
        "year": "2019",
        "date": "2019/5/2"
    },
    "version": 4
}