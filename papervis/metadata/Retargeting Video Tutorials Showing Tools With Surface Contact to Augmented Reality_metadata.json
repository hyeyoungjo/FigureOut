{
    "fullpath": "/Users/takyeonlee/Documents/work/_\u1109\u116e\u110b\u1165\u11b8_2021/ID503_Design_Project_1/_PaperVis/papers/VR_2017/Retargeting Video Tutorials Showing Tools With Surface Contact to Augmented Reality.pdf",
    "paper_id": "Retargeting Video Tutorials Showing Tools With Surface Contact to Augmented Reality",
    "venue": "VR_2017",
    "keywords": [
        "Augmented reality",
        "Virtual reality",
        "Retargeting",
        "Video tutorial"
    ],
    "paragraph_containing_keyword": "ABSTRACT\nA video tutorial effectively conveys complex motions, but\nmay be hard to follow precisely because of its restriction to\na predetermined viewpoint. Augmented reality (AR) tutori-\nals have been demonstrated to be more effective. We bring\nthe advantages of both together by interactively retargeting\nconventional, two-dimensional videos into three-dimensional\nAR tutorials. Unlike previous work, we do not simply overlay\nvideo, but synthesize 3D-registered motion from the video.\nSince the information in the resulting AR tutorial is registered\nto 3D objects, the user can freely change the viewpoint with-\nout degrading the experience. This approach applies to many\nstyles of video tutorials. In this work, we concentrate on a\nclass of tutorials which alter the surface of an object.\nACM Classi\ufb01cation Keywords\nH.5.1 Information Interfaces and Presentation: Multimedia In-\nformation Systems - Arti\ufb01cial, augmented and virtual realities\nAuthor Keywords\nAugmented reality;virtual reality;retargeting;video tutorial",
    "paragraph_after_keyword": "Permission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor pro\ufb01t or commercial advantage and that copies bear this notice and the full citation\non the \ufb01rst page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c permission\nand/or a fee. Request permissions from Permissions@acm.org.\nCHI 2017, May 06 \u2013 11, 2017, Denver, CO, USA\nCopyright is held by the owner/author(s). Publication rights licensed to ACM.\nACM 978-1-4503-4655-9/17/05...$15.00.\nDOI: http://dx.doi.org/10.1145/3025453.3025688",
    "doi": "10.1145/3025453.3025688",
    "sections": [
        {
            "word_count": 923,
            "figure_citations": {
                "1": [
                    "Figure 1 demonstrates drawing thick dots."
                ]
            },
            "section_index": 0,
            "title": "INTRODUCTION"
        },
        {
            "word_count": 732,
            "figure_citations": {},
            "section_index": 1,
            "title": "RELATED WORK"
        },
        {
            "word_count": 508,
            "figure_citations": {
                "2": [
                    "Figure 2), or the user interactively models the 3D object of interest.",
                    "Figure 2 (left) the system recognizes the face and automatically registers a deformable face mesh.",
                    "Figure 2 (middle), we retarget the trajectory of the make-up brush by registering the face mesh along with its previously generated 2D texture to the user\u2019s face.",
                    "Figure 2 (right), we abstract the motion by using one arrow for each segment of the trajectory.",
                    "Figure 2 (right), resulting in a presentation which uses arrows along the outline of the trajectory (see Figure 7)."
                ]
            },
            "section_index": 2,
            "title": "OVERVIEW"
        },
        {
            "word_count": 1223,
            "figure_citations": {
                "2": [
                    "Figure 2, a deformable model can be tracked by determining an update to the deformation parameters in each frame."
                ],
                "3": [
                    "Figure 3).",
                    "Figure 3).",
                    "Figure 3(b))."
                ]
            },
            "section_index": 3,
            "title": "EXTRACTION"
        },
        {
            "word_count": 608,
            "figure_citations": {
                "4": [
                    "Figure 4(c)."
                ],
                "2": [
                    "Figure 2 were originally applied to a jewelry box, but later retargeted to a teapot."
                ]
            },
            "section_index": 4,
            "title": "EDITING"
        },
        {
            "word_count": 458,
            "figure_citations": {
                "2": [
                    "Figure 2, middle)."
                ],
                "6": [
                    "Figure 6(b)), followed by an additional segmentation of the paths into smaller segments.",
                    "Figure 6(c) uses a threshold of 90\u25e6 ).",
                    "Figure 6(c))."
                ]
            },
            "section_index": 5,
            "title": "VISUALIZATION"
        },
        {
            "word_count": 1539,
            "figure_citations": {
                "5": [
                    "Figure 5 illustrates the video tutorial.",
                    "Figure 5(a)).",
                    "Figure 5(b)."
                ],
                "4": [
                    "Figure 4 illustrates the painting tutorial."
                ],
                "6": [
                    "Figure 6(d)).",
                    "Figure 6(d))."
                ]
            },
            "section_index": 6,
            "title": "EVALUATING THE AUTHORING"
        },
        {
            "word_count": 1534,
            "figure_citations": {
                "7": [
                    "Figure 7(c)).",
                    "Figure 7(a)).",
                    "Figure 7(a)).",
                    "Figure 7).",
                    "Figure 7).",
                    "Figure 7(b)).",
                    "Figure 7(b))."
                ],
                "8": [
                    "Figure 8 shows the boxplots of the measurements."
                ]
            },
            "section_index": 7,
            "title": "EVALUATING EFFICIENCY OF AR KANJI TUTORIAL"
        },
        {
            "word_count": 75,
            "figure_citations": {},
            "section_index": 8,
            "title": "SUS"
        },
        {
            "word_count": 796,
            "figure_citations": {},
            "section_index": 9,
            "title": "DISCUSSION AND FUTURE WORK"
        },
        {
            "word_count": 36,
            "figure_citations": {},
            "section_index": 10,
            "title": "ACKNOWLEDGMENTS"
        },
        {
            "word_count": 1419,
            "figure_citations": {},
            "section_index": 11,
            "title": "REFERENCES"
        }
    ],
    "title": "Retargeting Video Tutorials Showing Tools With Surface Contact to Augmented Reality",
    "authors": "Peter Mohr, David Mandl, Markus Tatzgern, Eduardo Veas, Dieter Schmalstieg, Denis Kalkofen",
    "abstract": "A video tutorial effectively conveys complex motions, but may be hard to follow precisely because of its restriction to a predetermined viewpoint. Augmented reality (AR) tutorials have been demonstrated to be more effective. We bring the advantages of both together by interactively retargeting conventional, two-dimensional videos into three-dimensional AR tutorials. Unlike previous work, we do not simply overlay video, but synthesize 3D-registered motion from the video. Since the information in the resulting AR tutorial is registered to 3D objects, the user can freely change the viewpoint without degrading the experience. This approach applies to many styles of video tutorials. In this work, we concentrate on a class of tutorials which alter the surface of an object.",
    "publication": {
        "venue": "CHI '17",
        "venue_full": "Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems",
        "year": "2017",
        "date": "2017/5/2"
    },
    "version": 4
}