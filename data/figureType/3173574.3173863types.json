{
    "1": {
        "type": "human",
        "caption_text": "Figure 1. Dyads performed the \ufb01rst (A) and second (B) tasks in the face-\nto-face conditions. In virtual reality conditions, avatars appeared across\nthe table from each other (C), but were actually positioned on opposite\nsides of the motion capture stage (D). In the embodVR condition, partic-\nipants were able to see both avatars (E). In the no_embodVR condition,\nparticipants were unable to see their partner and could only see their\nhands in the second task, to assist with furniture manipulation (F).\n",
        "image_labels": [
            [
                "Outerwear",
                0.9509767889976501
            ],
            [
                "Sleeve",
                0.8626784086227417
            ],
            [
                "Engineering",
                0.781038761138916
            ],
            [
                "Art",
                0.768406093120575
            ],
            [
                "Machine",
                0.7501384615898132
            ],
            [
                "Font",
                0.7449766397476196
            ],
            [
                "Technology",
                0.7409287691116333
            ],
            [
                "Games",
                0.684281051158905
            ],
            [
                "Flooring",
                0.6816161870956421
            ],
            [
                "Screenshot",
                0.6751130819320679
            ]
        ]
    },
    "2": {
        "type": "chart",
        "caption_text": "Figure 2. Sub \ufb01gure a shows the average number of gestures performed per minute for each condition. Sub\ufb01gure b shows the percentage of gestures that\nfall into each annotated category (note that, because some gestures \ufb01t multiple categories, totals for each condition can add up to over 100%). Sub\ufb01gure\nc shows the rate and percentage of gestures which introduced novel content into the discussions (for example, point at a location while referring to it by\na referential pronoun). Sub\ufb01gure d shows the mean number of conversational turns taken per minute. Sub\ufb01gure e shows the percent of utterances that\nfall in each annotated category (note that, because some gestures \ufb01t multiple categories, totals for each condition can add up to over 100%). Sub\ufb01gure\nf shows the frequencies of the manners by which conversational turns were started. Sub\ufb01gure g shows the ratio of gestures performed by the more\nfrequent gesturer and less frequent gesturer in each dyad. Sub\ufb01gure h shows the mean social presence scores, with standard errors of the mean, as\nmeasured by the semantic difference questionaire. Sub\ufb01gure i shows the most and least favorite conditions, as reported by participants at the end of the\nexperiment. All error bars show standard error of the mean.\n",
        "image_labels": [
            [
                "Rectangle",
                0.9098655581474304
            ],
            [
                "Product",
                0.9073331952095032
            ],
            [
                "Azure",
                0.8933658599853516
            ],
            [
                "Slope",
                0.8815410733222961
            ],
            [
                "Font",
                0.8552088141441345
            ],
            [
                "Parallel",
                0.7914196848869324
            ],
            [
                "Technology",
                0.7357338070869446
            ],
            [
                "Diagram",
                0.7348793745040894
            ],
            [
                "Pattern",
                0.725048303604126
            ],
            [
                "Electric blue",
                0.6990118026733398
            ]
        ]
    }
}