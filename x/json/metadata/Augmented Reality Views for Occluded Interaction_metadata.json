{
    "fullpath": "/Users/takyeonlee/Documents/work/_\u1109\u116e\u110b\u1165\u11b8_2021/ID503_Design_Project_1/_PaperVis/papers/chi2019xr/Augmented Reality Views for Occluded Interaction.pdf",
    "paper_id": "Augmented Reality Views for Occluded Interaction",
    "venue": "chi2019xr",
    "keywords": [
        "Augmented reality",
        "Manipulation task",
        "Finger-camera"
    ],
    "paragraph_containing_keyword": "CCS CONCEPTS\n\u2022 Human-centered computing \u2192 Mixed / augmented\nreality; Empirical studies in HCI .\nKEYWORDS\nAugmented reality, manipulation task, finger-camera\nACM Reference Format:\nKlemen Lilija, Henning Pohl, Sebastian Boring, and Kasper Hornb\u00e6k.\n2019. Augmented Reality Views for Occluded Interaction. In ACM\nConference on Human Factors in Computing Systems Proceedings (CHI\n2019), May 4\u20139, 2019, Glasgow, Scotland, UK. ACM, New York, NY,\nUSA, 12 pages. https://doi.org/10.1145/3290605.3300676",
    "doi": "10.1145/3290605.3300676",
    "paragraph_after_keyword": "Permission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies\nare not made or distributed for profit or commercial advantage and that\ncopies bear this notice and the full citation on the first page. Copyrights\nfor components of this work owned by others than the author(s) must\nbe honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific\npermission and/or a fee. Request permissions from permissions@acm.org.\nCHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK\n\u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed\nto ACM.\nACM ISBN 978-1-4503-5970-2/19/05. . . $15.00\nhttps://doi.org/10.1145/3290605.3300676",
    "sections": [
        {
            "word_count": 429,
            "figure_citations": {
                "1": [
                    "Figure 1)."
                ]
            },
            "section_index": 0,
            "title": "INTRODUCTION"
        },
        {
            "word_count": 983,
            "figure_citations": {},
            "section_index": 1,
            "title": "RELATED WORK"
        },
        {
            "word_count": 426,
            "figure_citations": {},
            "section_index": 2,
            "title": "TYPES OF OCCLUDED INTERACTION"
        },
        {
            "word_count": 774,
            "figure_citations": {
                "1": [
                    "Figure 1)."
                ]
            },
            "section_index": 3,
            "title": "VISUALIZING OCCLUDED OBJECTS"
        },
        {
            "word_count": 1733,
            "figure_citations": {
                "2": [
                    "Figure 2) were as follows: Pressing a Light Switch: Required either pressing (changing the state of) the left button, right button or both of the buttons on a two-button light switch.",
                    "Figure 2)."
                ],
                "3": [
                    "Figure 3a).",
                    "Figure 3b).",
                    "Figure 3c), to the left of the participants.",
                    "Figure 3a)."
                ],
                "4": [
                    "Figure 4)."
                ]
            },
            "section_index": 4,
            "title": "EVALUATING OCCLUDED INTERACTION VIEWS"
        },
        {
            "word_count": 2314,
            "figure_citations": {
                "5": [
                    "Figure 5, the manipulation delay differed between the views.",
                    "Figure 5 also shows how this delay differed depending on the task."
                ],
                "6": [
                    "Figure 6).",
                    "Figure 6)."
                ],
                "7": [
                    "Figure 7 shows how the view influenced the two kinds of manipulation Paper 446 Dynamic camera Cloned 3D See-through \u22120.",
                    "Figure 7 also shows the interactions between task and error."
                ],
                "8": [
                    "Figure 8).",
                    "Figure 8)."
                ]
            },
            "section_index": 5,
            "title": "RESULTS"
        },
        {
            "word_count": 869,
            "figure_citations": {},
            "section_index": 6,
            "title": "DISCUSSION"
        },
        {
            "word_count": 107,
            "figure_citations": {},
            "section_index": 7,
            "title": "CONCLUSION"
        },
        {
            "word_count": 25,
            "figure_citations": {},
            "section_index": 8,
            "title": "ACKNOWLEDGMENTS"
        },
        {
            "word_count": 1343,
            "figure_citations": {},
            "section_index": 9,
            "title": "REFERENCES"
        }
    ],
    "title": "Augmented Reality Views for Occluded Interaction",
    "authors": "Klemen Lilija, Henning Pohl, Sebastian Boring, Kasper Hornb\u00e6k",
    "abstract": "We rely on our sight when manipulating objects. When objects are occluded, manipulation becomes difficult. Such occluded objects can be shown via augmented reality to re-enable visual guidance. However, it is unclear how to do so to best support object manipulation. We compare four views of occluded objects and their effect on performance and satisfaction across a set of everyday manipulation tasks of varying complexity. The best performing views were a see-through view and a displaced 3D view. The former enabled participants to observe the manipulated object through the occluder, while the latter showed the 3D view of the manipulated object offset from the object's real location. The worst performing view showed remote imagery from a simulated hand-mounted camera. Our results suggest that alignment of virtual objects with their real-world location is less important than an appropriate point-of-view and view stability.",
    "publication": {
        "venue": "N/A",
        "venue_full": "Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
        "year": "2019",
        "date": "2019/5/2"
    },
    "version": 4
}