{
    "fullpath": "/Users/takyeonlee/Documents/work/_\u1109\u116e\u110b\u1165\u11b8_2021/ID503_Design_Project_1/_PaperVis/papers/chi2019xr/Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials.pdf",
    "paper_id": "Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials",
    "venue": "chi2019xr",
    "keywords": [
        "Force feedback",
        "EEG",
        "Elecrical muscle stimulation",
        "Virtual reality",
        "ERP",
        "Prediction error"
    ],
    "doi": "10.1145/3290605.3300657",
    "paragraph_containing_keyword": "response in unrealistic VR interaction, we also presented the\nfeedback prematurely in 25% of the trials.\nWe found that the early negativity component of the ERP\n(so called prediction error) was more pronounced in the\nmismatch trials, indicating we successfully detected haptic\nconflicts using our technique. Our results are a first step\ntowards using ERPs to automatically detect visuo-haptic\nmismatches in VR, such as those that can cause a loss of the\nuser\u2019s immersion.\nCCS CONCEPTS\n\u2022 Human-centered computing \u2192 Haptic devices; Vir-\ntual reality.\nKEYWORDS\nforce feedback; EEG; elecrical muscle stimulation; virtual\nreality; ERP; prediction error\nACM Reference Format:\nLukas Gehrke, Sezen Akman, Pedro Lopes, Albert Chen, Avinash\nKumar Singh, Hsiang-Ting Chen, Chin Teng Lin, and Klaus Gra-\nmann. 2019. Detecting Visuo-Haptic Mismatches in Virtual Reality\nusing the Prediction Error Negativity of Event-Related Brain Poten-\ntials. In CHI Conference on Human Factors in Computing Systems Pro-\nceedings (CHI 2019), May 4\u20139, 2019, Glasgow, Scotland Uk. ACM, New\nYork, NY, USA, 11 pages. https://doi.org/10.1145/3290605.3300657\n1 INTRO\nA key challenge in virtual reality is to create a user experi-\nence that mimics the natural experience as closely as possible.\nThis challenge has propelled advancements in display soft-\nware and hardware (VR headsets and rendering), interaction",
    "sections": [
        {
            "word_count": 343,
            "figure_citations": {},
            "section_index": 0,
            "title": "INTRO"
        },
        {
            "word_count": 672,
            "figure_citations": {},
            "section_index": 1,
            "title": "IMMERSION"
        },
        {
            "word_count": 782,
            "figure_citations": {},
            "section_index": 2,
            "title": "RELATED WORK"
        },
        {
            "word_count": 1852,
            "figure_citations": {
                "2": [
                    "Figure 2, comprised: (1) a VR headset and a wrist-mounted wearable VIVE tracker, (2) a 64-channel EEG system, (3) one vibrotactile actuator worn on the fingertip, and (4) a medically-compliant EMS device connected via two electrodes worn on the forearm."
                ],
                "3": [
                    "Figure 3, was as follows: (1) participants moved their hands from the resting position to the ready position, to indicate they were ready to start the next trial; (2) participants waited for a new target to appear (the time of a new target spawning was randomized between 1-2 s); (3) then, the target (a cube) would appear in one of three possible positions (center, left, right), all equidistant from the participant\u2019s ready position; (4) then, participants acquired the target by moving and touching the target with their index finger."
                ],
                "4": [
                    "Figure 4), we filtered the EEG data with a 0."
                ]
            },
            "section_index": 3,
            "title": "USER STUDY"
        },
        {
            "word_count": 1232,
            "figure_citations": {
                "4": [
                    "Figure 4(A).",
                    "Figure 4(B), we observed a negative deflection around 170ms after a participant had selected the object (i."
                ],
                "6": [
                    "Figure 6(B), we observed no significant differences for the peak latencies over the three conditions."
                ]
            },
            "section_index": 4,
            "title": "RESULTS"
        },
        {
            "word_count": 323,
            "figure_citations": {},
            "section_index": 5,
            "title": "CONCLUSIONS"
        },
        {
            "word_count": 19,
            "figure_citations": {},
            "section_index": 6,
            "title": "ACKNOWLEDGMENTS"
        },
        {
            "word_count": 1919,
            "figure_citations": {},
            "section_index": 7,
            "title": "REFERENCES"
        }
    ],
    "title": "Detecting Visuo-Haptic Mismatches in Virtual Reality using the Prediction Error Negativity of Event-Related Brain Potentials",
    "authors": "Lukas Gehrke, Sezen Akman, Pedro Lopes, Albert Chen, Avinash Kumar Singh, Hsiang-Ting Chen, Chin-Teng Lin, Klaus Gramann",
    "abstract": "Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion.",
    "publication": {
        "venue": "N/A",
        "venue_full": "Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
        "year": "2019",
        "date": "2019/5/2"
    },
    "version": 4
}