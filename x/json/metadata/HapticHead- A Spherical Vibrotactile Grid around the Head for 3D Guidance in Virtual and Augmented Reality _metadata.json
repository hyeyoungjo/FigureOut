{
    "fullpath": "/Users/takyeonlee/Documents/work/_\u1109\u116e\u110b\u1165\u11b8_2021/ID503_Design_Project_1/_PaperVis/papers/VR_2017/HapticHead- A Spherical Vibrotactile Grid around the Head for 3D Guidance in Virtual and Augmented Reality .pdf",
    "paper_id": "HapticHead- A Spherical Vibrotactile Grid around the Head for 3D Guidance in Virtual and Augmented Reality ",
    "venue": "VR_2017",
    "keywords": [
        "Guidance",
        "Navigation",
        "Haptic feedback",
        "Vibrotactile",
        "Virtual reality",
        "Augmented reality",
        "Spatial interaction",
        "3D output"
    ],
    "paragraph_containing_keyword": "ABSTRACT \nCurrent  virtual  and  augmented  reality  head-mounted  dis-\nplays usually include no or only a single vibration motor for \nhaptic feedback and do not use it for guidance. We present \nHapticHead,  a  system  utilizing  multiple  vibrotactile  actua-\ntors distributed in three concentric ellipses around the head \nfor intuitive haptic guidance through moving tactile cues. We \nconducted  three  experiments,  which  indicate  that  Hap-\nticHead vibrotactile feedback is both faster (2.6 s vs. 6.9 s) \nand more precise (96.4 % vs. 54.2 % success rate) than spa-\ntial audio (generic head-related transfer function) for finding \nvisible virtual objects in 3D space around the user. The base-\nline  of  visual  feedback  is  \u2013  as  expected  \u2013  more  precise \n(99.7 %  success  rate)  and  faster  (1.3 s)  in  comparison,  but \nthere are many applications in which visual feedback is not \ndesirable or available due to lighting conditions, visual over-\nload, or visual impairments. Mean final precision with Hap-\nticHead  feedback  on  invisible  targets  is  2.3\u00b0  compared  to \n0.8\u00b0 with visual feedback. We successfully navigated blind-\nfolded users to real household items at different heights using \nHapticHead vibrotactile feedback independently of a head-\nmounted display. \nAuthor Keywords \nGuidance; navigation; haptic feedback; vibrotactile; virtual \nreality; augmented reality; spatial interaction; 3D output \nACM Classification Keywords \nH.5.2.  Information  interfaces  and  presentation:  User  Inter-\nfaces \u2013 haptic I/O, input devices and strategies \nINTRODUCTION \nNavigation and 3D guidance systems use a large variety of \ndifferent  technologies  to  stimulate  the  visual,  auditory,  or \nhaptic channels. The visual channel is usually the channel of \nchoice as it typically has a higher bandwidth than the other \nchannels [29]. However, sometimes the visual channel is not \nthe  desired  primary  channel  to  be  used  for  some  kinds  of \nPermission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for profit or commercial advantage and that copies\nbear this notice and the full citation on the first page. Copyrights for com-\nponents of this work owned by others than ACM must be honored. Abstract-\ning  with  credit  is  permitted.  To  copy  otherwise,  or  republish,  to  post  on\nservers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from Permissions@acm.org. \nCHI 2017, May 06-11, 2017, Denver, CO, USA \n\u00a9 2017 ACM. ISBN 978-1-4503-4655-9/17/05\u2026$15.00 \nDOI: http://dx.doi.org/10.1145/3025453.3025684",
    "doi": "10.1145/3025453.3025684",
    "paragraph_after_keyword": "Figure 1. Placement of actuators in HapticHead. Note the three \nconcentric ellipses around the user\u2019s head and no actuators \nclose to the ear openings. The red ellipse contains 8 equidistant \nactuators, the green and blue ellipses each contain 6 actuators.\nfeedback or in special situations such as when driving a car \n[6].  The  visual  channel  might  be  overtaxed  and  important \nfeedback can be overlooked or lighting conditions may pre-\nvent the user from seeing the feedback at all. Another reason \nto use the tactile instead of the visual or auditory feedback \nchannels are faster initial reaction times, as shown in several \nstudies such as [25].  \nTo  relieve  the  visual  channel,  we  propose  HapticHead,  a \nhigh-resolution,  omnidirectional  vibrotactile  display  worn \non the head that presents 3D directional and distance infor-\nmation through moving tactile cues and patterns. It consists \nof a grid of vibrotactile actuators arranged in three concentric \nellipses around the head for uniform coverage, optimized for \nhead  shape  and  user  comfort  (Figure  1).  The  head  is  well \nsuited for guidance applications and tactile feedback, as it is \nsensitive to mechanical stimuli [9,18] and provides a large \nspherical  surface.  This  allows  displaying  precise  3D  infor-\nmation and allows the user to intuitively turn the head in the \ndirection of a stimulus. We left important parts of the face \nuncovered  and  did  not  place  actuators  too  close  (less  than \n4 cm) to the ear openings because noise through bone con-\nduction increases dramatically in their proximity.  \nHapticHead  may  be  combined  with  virtual  reality  (VR)  or \naugmented reality (AR) head-mounted displays (HMDs) to \nincrease  the  sense of  immersion.  The visual  content of  the \nHMD  is  then  synchronized  with  vibrotactile  feedback  of",
    "sections": [
        {
            "word_count": 943,
            "figure_citations": {},
            "section_index": 0,
            "title": "INTRODUCTION"
        },
        {
            "word_count": 192,
            "figure_citations": {},
            "section_index": 1,
            "title": "RELATED WORK"
        },
        {
            "word_count": 340,
            "figure_citations": {
                "2": [
                    "Figure 2) consists of a bathing cap with 17 vibration motors (Parallax, 12 mm coin type, 3.",
                    "Figure 2, left).",
                    "Figure 2)."
                ]
            },
            "section_index": 2,
            "title": "INITIAL PROTOTYPE"
        },
        {
            "word_count": 3016,
            "figure_citations": {
                "3": [
                    "Figure 3)."
                ],
                "2": [
                    "Figure 2, right)."
                ],
                "5": [
                    "Figure 5 show the measured dependent variables with merged data from all participants and all trials, not just successful ones."
                ],
                "4": [
                    "Figure 4 shows targets in front and back of the user for the auditory condition."
                ],
                "6": [
                    "Figure 6 shows, compared to auditory feedback, targets off the horizontal plane worked much better with vibrotactile feedback."
                ],
                "7": [
                    "Figure 7 shows the selection time by angular distance between the starting orientation of the user and the orientation of each target."
                ],
                "9": [
                    "Figure 9 shows the development of completion time over all trials."
                ],
                "11": [
                    "Figure 11 shows the success rates over time."
                ],
                "8": [
                    "Figure 8 shows the selection time by yaw (horizontal heading) distance between the starting orientation and each target."
                ],
                "10": [
                    "Figure 10)."
                ],
                "12": [
                    "Figure 12 and Figure 13)."
                ]
            },
            "section_index": 3,
            "title": "EXPERIMENTS"
        },
        {
            "word_count": 2929,
            "figure_citations": {
                "3": [
                    "Figure 3) were used, but here with tiny white 1-pixel targets instead of the large ones (4 repetitions \u00d7 20 targets per user)."
                ],
                "15": [
                    "Figure 15, participants agreed that the HapticHead vibrotactile feedback was helpful for finding virtual targets and most of the participants could intuitively map the feedback to the targets.",
                    "Figure 15, participants found the vibrotactile feedback helpful for finding real targets around them and could intuitively map vibrotactile signals to targets, thus research question 2 can be answered positively."
                ],
                "16": [
                    "Figure 16)."
                ]
            },
            "section_index": 4,
            "title": "REFINEMENT OF CONCEPT AND PROTOTYPE"
        },
        {
            "word_count": 184,
            "figure_citations": {},
            "section_index": 5,
            "title": "CONCLUSION"
        },
        {
            "word_count": 63,
            "figure_citations": {},
            "section_index": 6,
            "title": "LIMITATIONS"
        },
        {
            "word_count": 874,
            "figure_citations": {},
            "section_index": 7,
            "title": "REFERENCES"
        }
    ],
    "title": "HapticHead: A Spherical Vibrotactile Grid around the Head for 3D Guidance in Virtual and Augmented Reality",
    "authors": "Oliver Beren Kaul, Michael Rohs",
    "abstract": "Current virtual and augmented reality head-mounted displays usually include no or only a single vibration motor for haptic feedback and do not use it for guidance. We present HapticHead, a system utilizing multiple vibrotactile actuators distributed in three concentric ellipses around the head for intuitive haptic guidance through moving tactile cues. We conducted three experiments, which indicate that HapticHead vibrotactile feedback is both faster (2.6 s vs. 6.9 s) and more precise (96.4% vs. 54.2% success rate) than spatial audio (generic head-related transfer function) for finding visible virtual objects in 3D space around the user. The baseline of visual feedback is as expected more precise (99.7% success rate) and faster (1.3 s) in comparison, but there are many applications in which visual feedback is not desirable or available due to lighting conditions, visual overload, or visual impairments. Mean final precision with HapticHead feedback on invisible targets is 2.3\u00b0 compared to 0.8\u00b0 with visual feedback. We successfully navigated blindfolded users to real household items at different heights using HapticHead vibrotactile feedback independently of a head-mounted display.",
    "publication": {
        "venue": "CHI '17",
        "venue_full": "Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems",
        "year": "2017",
        "date": "2017/5/2"
    },
    "version": 4
}