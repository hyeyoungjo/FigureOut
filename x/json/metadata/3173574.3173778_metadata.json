{
    "fullpath": "/Users/takyeonlee/Documents/work/_\u1109\u116e\u110b\u1165\u11b8_2021/ID503_Design_Project_1/_PaperVis/papers/CHI 18/3173574.3173778.pdf",
    "paper_id": "3173574.3173778",
    "venue": "CHI 18",
    "keywords": [
        "Visualization",
        "Assistive technology",
        "Autism",
        "Proximity",
        "Prosody",
        "Immersive VR",
        "Accessibility"
    ],
    "paragraph_containing_keyword": "ABSTRACT \nnuanced \ncommunication \nSocial \nnonverbal  communication  cues, \nincluding  eye  contact, \ngestures,  facial  expressions,  body  language,  and  tone  of \nvoice. This type  of communication  is central to face-to-face \ninteraction,  but  can  be  challenging  for  children  and  adults \nwith autism. Innovative technologies can provide support by \naugmenting \nautomated \nprompting. Specifically, immersive virtual reality (VR) offers \nan  option \ninterventions  by \nin  real-time  social \ninformation \nconcretizing  nonverbal \ninteractions.  In  this  work,  we  explore  the  design  and \nevaluation of three nonverbal communication applications in \nimmersive  VR.  The  results  of  this  work  indicate  that \ndelivering  real-time  visualizations  of  proximity,  speaker \nvolume,  and  duration  of  one\u2019s  speech  is  feasible  in \nimmersive  VR  and  effective  for  real-time  support  for \nproximity  regulation  for  children  with  autism.  We  conclude \nwith design considerations for therapeutic VR systems. \nAUTHOR KEYWORDS \nVisualization; \nassistive \ntechnology;  autism;  proximity;  prosody;  immersive  VR; \naccessibility.  \nACM Classification Keywords \nK.4.2. [Social Issues] Assistive technologies for persons with \ndisabilities; Artificial, augmented, and virtual realities \nINTRODUCTION \nSocial  communication  is  essential  to  quality  of  life.  The \nability  to  express  one\u2019s  own  needs  and  wants  while \nunderstanding  others  is  central  to  our  connection  to  one \nanother  and  our  ability  to  teach  and  learn.    Challenges  with \nsocial  communication  have  the  ability  to  put  human \nPermission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for \npersonal or classroom use is granted without fee provided that copies are \nnot made or distributed for profit or commercial advantage and that copies \nbear  this  notice  and  the  full  citation  on  the  first  page.  Copyrights  for \ncomponents  of  this  work  owned  by  others  than  ACM  must  be  honored. \nAbstracting  with  credit  is  permitted.  To  copy  otherwise,  or  republish,  to \npost on servers or to redistribute to lists, requires prior specific permission \nand/or a fee. Request permissions from Permissions@acm.org. \nCHI 2018, April 21\u201326, 2018, Montreal, QC, Canada  \n\u00a9 2018 Association for Computing Machinery. \nACM ISBN 978-1-4503-5620-6/18/04\u2026$15.00  \nhttps://doi.org/10.1145/3173574.3173778",
    "doi": "10.1145/3173574.3173778",
    "paragraph_after_keyword": "communication;",
    "sections": [
        {
            "word_count": 30,
            "figure_citations": {},
            "section_index": 0,
            "title": "AUTHOR KEYWORDS"
        },
        {
            "word_count": 660,
            "figure_citations": {},
            "section_index": 1,
            "title": "INTRODUCTION"
        },
        {
            "word_count": 796,
            "figure_citations": {},
            "section_index": 2,
            "title": "RELATED WORK"
        },
        {
            "word_count": 1458,
            "figure_citations": {
                "2": [
                    "Figure 2B) did not result in changing one\u2019s proximity when needed; and c.",
                    "Figure 2A).",
                    "Figure 2B), and yellow representing an intermediate warning between the two zones (see Figure 2D).",
                    "Figure 2E).",
                    "Figure 2D) or \u2018step away\u2019 respectively (see Figure 2 E).",
                    "Figure 2C)."
                ],
                "1": [
                    "Figure 1-time spent talking bar)."
                ]
            },
            "section_index": 3,
            "title": "SYSTEM DESIGN"
        },
        {
            "word_count": 830,
            "figure_citations": {},
            "section_index": 4,
            "title": "EVALUATION"
        },
        {
            "word_count": 2223,
            "figure_citations": {
                "3": [
                    "Figure 3, left).",
                    "Figure 3, middle), yet at the Paper 204 individual level, three participants improved in the intervention condition (P1, P9, P11), three performed well in baseline and intervention (P2, P6, P8), and three showed reduced performance in the intervention condition (P5, P7, P10).",
                    "Figure 3, right)."
                ]
            },
            "section_index": 5,
            "title": "RESULTS"
        },
        {
            "word_count": 1200,
            "figure_citations": {},
            "section_index": 6,
            "title": "DESIGN CONSIDERATIONS FOR THERAPUETIC VR"
        },
        {
            "word_count": 351,
            "figure_citations": {},
            "section_index": 7,
            "title": "DISCUSSION"
        },
        {
            "word_count": 169,
            "figure_citations": {},
            "section_index": 8,
            "title": "CONCLUSION"
        },
        {
            "word_count": 48,
            "figure_citations": {},
            "section_index": 9,
            "title": "ACKNOWLEDGMENTS"
        },
        {
            "word_count": 1288,
            "figure_citations": {},
            "section_index": 10,
            "title": "REFERENCES"
        }
    ],
    "title": "vrSocial: Toward Immersive Therapeutic VR Systems for Children with Autism",
    "authors": "LouAnne E. Boyd, Saumya Gupta, Sagar B. Vikmani, Carlos M. Gutierrez, Junxiang Yang, Erik Linstead, Gillian R. Hayes",
    "abstract": "Social communication frequently includes nuanced nonverbal communication cues, including eye contact, gestures, facial expressions, body language, and tone of voice. This type of communication is central to face-to-face interaction, but can be challenging for children and adults with autism. Innovative technologies can provide support by augmenting human-delivered cuing and automated prompting. Specifically, immersive virtual reality (VR) offers an option to generalize social skill interventions by concretizing nonverbal information in real-time social interactions. In this work, we explore the design and evaluation of three nonverbal communication applications in immersive VR. The results of this work indicate that delivering real-time visualizations of proximity, speaker volume, and duration of one's speech is feasible in immersive VR and effective for real-time support for proximity regulation for children with autism. We conclude with design considerations for therapeutic VR systems.",
    "publication": {
        "venue": "CHI '18",
        "venue_full": "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems",
        "year": "2018",
        "date": "2018/4/21"
    },
    "version": 3
}