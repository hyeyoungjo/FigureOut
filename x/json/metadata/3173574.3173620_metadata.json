{
    "fullpath": "/Users/takyeonlee/Documents/work/_\u1109\u116e\u110b\u1165\u11b8_2021/ID503_Design_Project_1/_PaperVis/papers/CHI 18/3173574.3173620.pdf",
    "paper_id": "3173574.3173620",
    "venue": "CHI 18",
    "keywords": [
        "Mixed reality",
        "Remote collaboration",
        "Augmented reality",
        "Virtual reality",
        "Remote embodiment",
        "Avatar",
        "Redirected",
        "Gaze",
        "Gesture",
        "Awareness"
    ],
    "doi": "10.1145/3173574.3173620",
    "paragraph_containing_keyword": "Author Keywords \nMixed  reality;  remote  collaboration;  augmented  reality; \nvirtual  reality;  remote  embodiment;  avatar;  redirected,  gaze, \ngesture; awareness.  \nACM Classification Keywords \nH.5.1.  Information  interfaces  and  presentation  (e.g.,  HCI): \nMultimedia  Information  Systems\u2014Artificial,  augmented, \nand virtual realities. \nINTRODUCTION \nThis paper explores how adaptive avatars can improve Mixed \nReality (MR) remote collaboration. MR is a technology that \nseamlessly bridges real and virtual worlds. In the near future, \nMR  collaboration  between  users  in  the  real  world  using \nAugmented Reality (AR) and remote users in Virtual Reality \n(VR)  may  be  commonplace.  A  MR  remote  collaboration \ninvolves a local AR user sharing their real-world information \nwith a remote VR user, such as the reconstructed task space \nnecessary for spatial awareness and understanding. Like any \nremote  collaborative  systems,  one  of  the  main  goals  of  MR \ncollaboration is to enable people to feel  co-present.  AR and",
    "sections": [
        {
            "word_count": 502,
            "figure_citations": {},
            "section_index": 0,
            "title": "INTRODUCTION"
        },
        {
            "word_count": 3685,
            "figure_citations": {
                "2": [
                    "Figure 2a and 2b).",
                    "Figure 2c and 2d).",
                    "Figure 2e and 2f)."
                ],
                "3": [
                    "Figure 3 shows an example of this with an application named \u201cSnow Dome,\u201d a remote MR collaboration application that demonstrates how AR and VR collaboration can be enhanced with multi-scale interaction.",
                    "Figure 3a.",
                    "Figure 3b."
                ]
            },
            "section_index": 1,
            "title": "RELATED WORK"
        },
        {
            "word_count": 3526,
            "figure_citations": {
                "3": [
                    "Figure 3d and 3e show the original AR space and the result of the reconstruction showed to the VR user."
                ],
                "4": [
                    "Figure 4).",
                    "Figure 4).",
                    "Figure 4)."
                ]
            },
            "section_index": 2,
            "title": "USER STUDY"
        },
        {
            "word_count": 610,
            "figure_citations": {},
            "section_index": 3,
            "title": "DISCUSSION"
        },
        {
            "word_count": 257,
            "figure_citations": {},
            "section_index": 4,
            "title": "CONCLUSION AND FUTURE WORK"
        },
        {
            "word_count": 23,
            "figure_citations": {},
            "section_index": 5,
            "title": "ACKNOWLEDGMENTS"
        },
        {
            "word_count": 1623,
            "figure_citations": {},
            "section_index": 6,
            "title": "REFERENCES"
        }
    ],
    "title": "Mini-Me: An Adaptive Avatar for Mixed Reality Remote Collaboration",
    "authors": "Thammathip Piumsomboon, Gun A. Lee, Jonathon D. Hart, Barrett Ens, Robert W. Lindeman, Bruce H. Thomas, Mark Billinghurst",
    "abstract": "We present Mini-Me, an adaptive avatar for enhancing Mixed Reality (MR) remote collaboration between a local Augmented Reality (AR) user and a remote Virtual Reality (VR) user. The Mini-Me avatar represents the VR user's gaze direction and body gestures while it transforms in size and orientation to stay within the AR user's field of view. A user study was conducted to evaluate Mini-Me in two collaborative scenarios: an asymmetric remote expert in VR assisting a local worker in AR, and a symmetric collaboration in urban planning. We found that the presence of the Mini-Me significantly improved Social Presence and the overall experience of MR collaboration.",
    "publication": {
        "venue": "CHI '18",
        "venue_full": "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems",
        "year": "2018",
        "date": "2018/4/21"
    },
    "version": 3
}